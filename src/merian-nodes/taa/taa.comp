#version 460
#extension GL_GOOGLE_include_directive              : enable

#include "config.h"
#include "common/sampler.glsl"

// Good blog post on TAA: https://www.elopezr.com/temporal-aa-and-the-quest-for-the-holy-trail/

layout(local_size_x_id = 0, local_size_y_id = 1, local_size_z = 1) in;

layout(constant_id = 2) const int INVERSE_MOTION = 0;

layout(set = 0, binding = 0) uniform sampler2D img_current_frame;
layout(set = 0, binding = 1) uniform sampler2D img_previous_frame;
layout(set = 0, binding = 2) uniform sampler2D img_mv; // in pixels

layout(set = 0, binding = 3) uniform writeonly image2D img_out;

layout(push_constant) uniform PushConstant { 
    // higher value means more temporal reuse
    float temporal_alpha;
    int clamp_method;
} params;

// texel_coord in pixels
vec4 texelFetchClamp(const ivec2 texel_coord, sampler2D texture) {
    const ivec2 coord = clamp(texel_coord, ivec2(0), textureSize(texture, 0) - ivec2(1));
    return texelFetch(texture, coord, 0);
}

// Find longest motion vector inside a window, return motion vector in texture space (i.e. [0,1]^2)!
// 
// Reason:
// When reprojecting the current pixel, we need to realize that the velocity texture, unlike the history color buffer, is aliased.
// If we’re not careful we could be reintroducing edge aliasing indirectly. To better account for the edges, a typical solution is to dilate the aliased information.
// We’ll use velocity as an example but you can do this with depth and stencil. There are a couple of ways I know of doing it:
// 
// - (here:) Magnitude Dilation: take the velocity with the largest magnitude in a neighborhood
// - (also possible:) Depth Dilation: take the velocity that corresponds to the pixel with the nearest depth in a neighborhood
vec2 sample_motion_vector(const ivec2 center_pixel, const int radius) {
    // find longest motion vector, transform into texture space
    // access pixes position of the current fragment with ivec2(gl_FragCoord.xy)
    
    vec2 longest = vec2(0., 0.);
    for (int j = -radius; j <= radius; ++j) {
        for (int i = -radius; i <= radius; ++i) {
            const vec2 mv = texelFetchClamp(center_pixel + ivec2(j, i), img_mv).rg;
            if (length(mv) > length(longest)) {
                longest = mv;
            }
        }
    }

    return longest;
}

vec4 merge_frames(const vec4 current_color,
                  vec4 previous_color,
                  const float alpha,
                  const ivec2 pixel) {
    switch(params.clamp_method) {
    case MERIAN_NODES_TAA_CLAMP_NONE:
        break;
    case MERIAN_NODES_TAA_CLAMP_MIN_MAX:
        vec4 neigh_clamp_min_color = vec4(1. / 0.);
        vec4 neigh_clamp_max_color = vec4(-1. / 0.);
        for (int j = -1; j <= 1; ++j) {
            for (int i = -1; i <= 1; ++i) {
                const vec4 color = texelFetchClamp(pixel + ivec2(j, i), img_current_frame);
                neigh_clamp_min_color = min(neigh_clamp_min_color, color);
                neigh_clamp_max_color = max(neigh_clamp_max_color, color);
            }
        }
        previous_color = clamp(previous_color, neigh_clamp_min_color, neigh_clamp_max_color);
        break;
    case 2:
        vec4 m1 = vec4(0.0f);
        vec4 m2 = vec4(0.0f);
        const int r = 1;
        for (int yy=-r; yy<=r; yy++)
            for(int xx=-r; xx<=r; xx++) {
                const vec4 b = texelFetchClamp(pixel + ivec2(xx, yy), img_current_frame);
                m1 += b;
                m2 += b * b;
            }
        m1 /= (2.0 * r + 1) * (2.0 * r + 1);
        m2 /= (2.0 * r + 1) * (2.0 * r + 1);
        const vec4 sigma = sqrt(max(vec4(0), m2 - m1 * m1));
        const float thresh = 1.0;//params.rejection_threshold;
        previous_color = clamp(previous_color, max(vec4(0), m1 - thresh * sigma), m1 + thresh * sigma);
        break;
    default:
        return vec4(1, 0, 1, 1);
    }

    return mix(current_color, previous_color, alpha);
}

void main() {
    const ivec2 pixel = ivec2(gl_GlobalInvocationID);
    const ivec2 resolution = ivec2(imageSize(img_out));
    if (any(greaterThanEqual(pixel, resolution)))
        return;

    vec2 motion_vector = sample_motion_vector(pixel, 1);
    if (INVERSE_MOTION > 0) {
        motion_vector *= -1;
    }

    const vec4 current_color = texelFetch(img_current_frame, pixel, 0);
    vec4 previous_color = catmull_rom(img_previous_frame, (pixel + motion_vector + .5) / vec2(resolution));

    // previous texture is never initialized and might contain NaN (prevent poisoning)
    if(any(isnan(previous_color)) || any(isinf(previous_color)))
        previous_color = current_color;

    const vec4 merged = merge_frames(current_color, previous_color, params.temporal_alpha, pixel);
    imageStore(img_out, pixel, merged);
}
